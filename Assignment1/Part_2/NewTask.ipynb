{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba5e130d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports and Setup\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.datasets import make_moons\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from train_mlp_numpy import train\n",
    "from mlp_numpy import MLP\n",
    "from modules import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b4c503e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data Generation and Preprocessing\n",
    "X, y_scalar = make_moons(n_samples=1000, noise=0.02, random_state=42)\n",
    "\n",
    "# Visualize the raw data\n",
    "plt.figure(figsize=(8, 6))\n",
    "plt.scatter(X[:, 0], X[:, 1], c=y_scalar, s=40, cmap=plt.cm.RdYlBu)\n",
    "plt.title('Visualization of the Raw Moons Dataset')\n",
    "plt.xlabel('Feature 1')\n",
    "plt.ylabel('Feature 2')\n",
    "plt.grid(True)\n",
    "plt.show()\n",
    "\n",
    "\n",
    "y_one_hot = np.zeros((len(y_scalar), 2))\n",
    "y_one_hot[np.arange(len(y_scalar)), y_scalar] = 1\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y_one_hot, test_size=0.2, random_state=42)\n",
    "\n",
    "# Bundle data for the train function\n",
    "data_tuple = (X_train, y_train, X_test, y_test)\n",
    "print(f\"Training data shape: {X_train.shape}\")\n",
    "print(f\"Testing data shape: {X_test.shape}\")\n",
    "\n",
    "\n",
    "def plot_single_experiment_results(steps, train_accs, test_accs, loss_log, batch_size_title):\n",
    "    \"\"\"\n",
    "    Creates two plots for a single experiment:\n",
    "    1. Training & Testing Accuracy vs. Epoch\n",
    "    2. Loss vs. Epoch\n",
    "    \"\"\"\n",
    "    # Create a figure with two subplots, one above the other\n",
    "    fig, (ax1, ax2) = plt.subplots(2, 1, figsize=(12, 10), sharex=True)\n",
    "    \n",
    "    # --- Plot 1: Accuracy ---\n",
    "    title_prefix = f\"Batch Size = {batch_size_title}\" if isinstance(batch_size_title, int) else \"Batch Size = Full(BGD)\"\n",
    "    \n",
    "    ax1.plot(steps, train_accs, label='Train Accuracy', marker='o', linestyle='-', markersize=4, markevery=1)\n",
    "    ax1.plot(steps, test_accs, label='Test Accuracy', marker='x', linestyle='--', markersize=6, markevery=1)\n",
    "    ax1.set_ylabel('Accuracy')\n",
    "    ax1.set_ylim(0.47, 1.01)\n",
    "    ax1.set_title(f'{title_prefix}: Accuracy with Epoch')\n",
    "    ax1.grid(True)\n",
    "    ax1.legend()\n",
    "    \n",
    "    # --- Plot 2: Loss ---\n",
    "    ax2.plot(steps, loss_log, label='Loss', marker='s', linestyle='-.', color='green', markersize=4, markevery=1)\n",
    "    ax2.set_ylabel('Loss')\n",
    "    ax2.set_xlabel('Epoch')\n",
    "    ax2.set_title(f'{title_prefix}: Loss with Epoch')\n",
    "    ax2.grid(True)\n",
    "    ax2.legend()\n",
    "    \n",
    "    # Adjust layout to prevent titles from overlapping\n",
    "    plt.tight_layout(pad=3.0)\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "def plot_decision_boundary(model, X, y_scalar, batch_size_title):\n",
    "    plt.figure(figsize=(8, 6))\n",
    "    \n",
    "    x_min, x_max = X[:, 0].min() - 0.5, X[:, 0].max() + 0.5\n",
    "    y_min, y_max = X[:, 1].min() - 0.5, X[:, 1].max() + 0.5\n",
    "    \n",
    "    xx, yy = np.meshgrid(np.arange(x_min, x_max, 0.02),\n",
    "                         np.arange(y_min, y_max, 0.02))\n",
    "    \n",
    "    grid_points = np.c_[xx.ravel(), yy.ravel()]\n",
    "    \n",
    "    logits = model.forward(grid_points)\n",
    "    softmax_layer = SoftMax()\n",
    "    probs = softmax_layer.forward(logits)\n",
    "    Z = np.argmax(probs, axis=1)\n",
    "    Z = Z.reshape(xx.shape)\n",
    "    \n",
    "    plt.contourf(xx, yy, Z, alpha=0.8, cmap=plt.cm.RdYlBu)\n",
    "    plt.scatter(X[:, 0], X[:, 1], c=y_scalar, s=40, edgecolors='k', cmap=plt.cm.RdYlBu)\n",
    "    \n",
    "    title = f'Decision Boundary (Batch Size = {batch_size_title})'\n",
    "    plt.title(title)\n",
    "    plt.xlabel('Feature 1')\n",
    "    plt.ylabel('Feature 2')\n",
    "    plt.grid(True)\n",
    "    plt.show()\n",
    "\n",
    "def plot_decision_boundary(model, X, y_scalar, batch_size_title):\n",
    "    \"\"\"Plots the decision boundary for a trained model.\"\"\"\n",
    "    plt.figure(figsize=(8, 6))\n",
    "    \n",
    "    x_min, x_max = X[:, 0].min() - 0.5, X[:, 0].max() + 0.5\n",
    "    y_min, y_max = X[:, 1].min() - 0.5, X[:, 1].max() + 0.5\n",
    "    \n",
    "    xx, yy = np.meshgrid(np.arange(x_min, x_max, 0.02),\n",
    "                         np.arange(y_min, y_max, 0.02))\n",
    "    \n",
    "    grid_points = np.c_[xx.ravel(), yy.ravel()]\n",
    "    \n",
    "    # Perform forward pass to get predictions\n",
    "    logits = model.forward(grid_points)\n",
    "    softmax_layer = SoftMax() # The softmax layer is external to the MLP\n",
    "    probs = softmax_layer.forward(logits)\n",
    "    Z = np.argmax(probs, axis=1)\n",
    "    Z = Z.reshape(xx.shape)\n",
    "    \n",
    "    # Plot the colored decision regions\n",
    "    plt.contourf(xx, yy, Z, alpha=0.8, cmap=plt.cm.RdYlBu)\n",
    "    \n",
    "    # Overlay the original data points\n",
    "    plt.scatter(X[:, 0], X[:, 1], c=y_scalar, s=40, edgecolors='k', cmap=plt.cm.RdYlBu)\n",
    "    \n",
    "    title = f'Decision Boundary (Batch Size = {batch_size_title})'\n",
    "    plt.title(title)\n",
    "    plt.xlabel('Feature 1')\n",
    "    plt.ylabel('Feature 2')\n",
    "    plt.grid(True)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2027556",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Define Hyperparameters for the Experiments ---\n",
    "DNN_HIDDEN_UNITS = '20,20'\n",
    "MAX_EPOCHS = 100000\n",
    "EVAL_FREQ = 1000\n",
    "\n",
    "# --- List of Batch Sizes to Test ---\n",
    "# We'll test SGD (1), a few mini-batch sizes, and BGD ('full')\n",
    "EXPERIMENT_CONFIGS = {\n",
    "    'full': 1\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b752623",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Block 6: The Experiment Loop\n",
    "\n",
    "# Dictionaries to store the results\n",
    "results_history = {}\n",
    "trained_models = {}\n",
    "\n",
    "print(\"Starting training experiments with custom learning rates...\")\n",
    "\n",
    "# Iterate through the dictionary to get both batch_size and its paired learning_rate\n",
    "for bs, lr in EXPERIMENT_CONFIGS.items():\n",
    "    print(f\"\\n{'='*20} TRAINING WITH BATCH SIZE: {bs}, LEARNING RATE: {lr} {'='*20}\")\n",
    "    \n",
    "    # Call the train function with the specific LR for this run\n",
    "    # (This still assumes your train function returns the final model object)\n",
    "    steps, train_accs, test_accs, loss_log, final_model = train(\n",
    "        data=data_tuple,\n",
    "        dnn_hidden_units=DNN_HIDDEN_UNITS,\n",
    "        learning_rate=lr,  \n",
    "        max_steps=MAX_EPOCHS,\n",
    "        eval_freq=EVAL_FREQ,\n",
    "        batch_size=bs,\n",
    "        momentum = 0.6,\n",
    "        leaky = True\n",
    "    )\n",
    "    print(f\"\\n--- Results for Batch Size: {bs} ---\")\n",
    "    plot_single_experiment_results(steps, train_accs, test_accs, loss_log, batch_size_title=bs)\n",
    "    \n",
    "    # Store results for plotting accuracy curves\n",
    "    results_history[bs] = {\n",
    "        'steps': steps,\n",
    "        'train_accs': train_accs,\n",
    "        'test_accs': test_accs,\n",
    "        'loss': loss_log\n",
    "    }\n",
    "    \n",
    "    # Store the trained model for visualizing the decision boundary\n",
    "    trained_models[bs] = final_model\n",
    "\n",
    "print(\"\\nAll training experiments completed!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6c86835",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Block 7: Visualize All Decision Boundaries\n",
    "print(\"\\nVisualizing the decision boundary for each model...\")\n",
    "for bs, model in trained_models.items():\n",
    "    plot_decision_boundary(model, X, y_scalar, batch_size_title=bs)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
